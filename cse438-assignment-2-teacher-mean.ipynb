{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13576387,"sourceType":"datasetVersion","datasetId":8624798}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q ultralytics albumentations --no-deps","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:01:32.033022Z","iopub.execute_input":"2025-12-16T09:01:32.033789Z","iopub.status.idle":"2025-12-16T09:01:38.040128Z","shell.execute_reply.started":"2025-12-16T09:01:32.033748Z","shell.execute_reply":"2025-12-16T09:01:38.037610Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Copy dataset to working directory**","metadata":{}},{"cell_type":"code","source":"!cp -r \"/kaggle/input/waste-detection/waste detection data/\" \"/kaggle/working/dataset\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:01:38.041330Z","iopub.execute_input":"2025-12-16T09:01:38.041699Z","iopub.status.idle":"2025-12-16T09:04:15.282474Z","shell.execute_reply.started":"2025-12-16T09:01:38.041655Z","shell.execute_reply":"2025-12-16T09:04:15.281069Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Generating yaml config file ","metadata":{}},{"cell_type":"code","source":"from ruamel.yaml import YAML\nimport os\n\nROOT_TRAINING_FOLDER = \"/kaggle/working/dataset\"\n# Correct the paths in the data dictionary\ndata = {\n    'train': os.path.join(ROOT_TRAINING_FOLDER, 'train', 'images'),\n    'val': os.path.join(ROOT_TRAINING_FOLDER, 'valid', 'images'),\n    'nc': 7,\n    'names': ['Aluminium', 'Glass', 'Tag', 'cardboard', 'rigid_plastic', 'soft_plastic', 'wood']\n}\n\nyaml = YAML()\nwith open('data.yaml', 'w') as f:\n    yaml.dump(data, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:15.285327Z","iopub.execute_input":"2025-12-16T09:04:15.285680Z","iopub.status.idle":"2025-12-16T09:04:15.501847Z","shell.execute_reply.started":"2025-12-16T09:04:15.285649Z","shell.execute_reply":"2025-12-16T09:04:15.500672Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load dataset and create yaml","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/working/data.yaml\n# ============================================================\n# YOLOv12 Dataset Configuration for Instance Segmentation\n# ============================================================\n\ntrain: /kaggle/working/dataset/train\nval: /kaggle/working/dataset/valid\ntest: /kaggle/working/dataset/test\n\n# Number of classes\nnc: 7\n\n# Class names\nnames: ['Aluminium','Glass','Tag','cardboard ', ' rigid_plastic','soft_plastic','wood']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:15.503116Z","iopub.execute_input":"2025-12-16T09:04:15.503447Z","iopub.status.idle":"2025-12-16T09:04:15.513286Z","shell.execute_reply.started":"2025-12-16T09:04:15.503419Z","shell.execute_reply":"2025-12-16T09:04:15.511996Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/data.yaml\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Check and verify dataset","metadata":{}},{"cell_type":"code","source":"from ultralytics.data.utils import check_det_dataset\n\ncheck_det_dataset('/kaggle/working/data.yaml')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:15.514705Z","iopub.execute_input":"2025-12-16T09:04:15.515425Z","iopub.status.idle":"2025-12-16T09:04:21.765750Z","shell.execute_reply.started":"2025-12-16T09:04:15.515387Z","shell.execute_reply":"2025-12-16T09:04:21.764817Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 75.9MB/s 0.0s\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'train': '/kaggle/working/dataset/train',\n 'val': '/kaggle/working/dataset/valid',\n 'test': '/kaggle/working/dataset/test',\n 'nc': 7,\n 'names': {0: 'Aluminium',\n  1: 'Glass',\n  2: 'Tag',\n  3: 'cardboard ',\n  4: ' rigid_plastic',\n  5: 'soft_plastic',\n  6: 'wood'},\n 'yaml_file': '/kaggle/working/data.yaml',\n 'channels': 3,\n 'path': PosixPath('/kaggle/working')}"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os, glob, random, shutil, cv2\nimport numpy as np\nimport torch\nimport albumentations as A\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:21.767073Z","iopub.execute_input":"2025-12-16T09:04:21.767589Z","iopub.status.idle":"2025-12-16T09:04:28.494743Z","shell.execute_reply.started":"2025-12-16T09:04:21.767562Z","shell.execute_reply":"2025-12-16T09:04:28.493693Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"BASE_DATASET = \"/kaggle/working/dataset\"  # your dataset root\nDATA_YAML    = \"/kaggle/working/data.yaml\"          # your baseline yaml (already exists)\n\nLABELED_PATH   = \"/kaggle/working/ts_labeled\"\nUNLABELED_PATH = \"/kaggle/working/ts_unlabeled\"\nPSEUDO_PATH    = \"/kaggle/working/ts_pseudo\"\nMERGED_PATH    = \"/kaggle/working/ts_merged\"\n\nos.makedirs(f\"{LABELED_PATH}/images\", exist_ok=True)\nos.makedirs(f\"{LABELED_PATH}/labels\", exist_ok=True)\nos.makedirs(f\"{UNLABELED_PATH}/images\", exist_ok=True)\nos.makedirs(f\"{UNLABELED_PATH}/labels\", exist_ok=True)\nos.makedirs(f\"{PSEUDO_PATH}/images\", exist_ok=True)\nos.makedirs(f\"{PSEUDO_PATH}/labels\", exist_ok=True)\nos.makedirs(f\"{MERGED_PATH}/images\", exist_ok=True)\nos.makedirs(f\"{MERGED_PATH}/labels\", exist_ok=True)\n\nNUM_CLASSES = 7\nCLASS_NAMES = ['Aluminium','Glass','Tag','cardboard ', ' rigid_plastic','soft_plastic','wood']\n\nLABELED_FRACTION = 0.2   # 20% labeled, 80% unlabeled\nTEACHER_EPOCHS   = 10\nSTUDENT_EPOCHS   = 20\nIMGSZ            = 640\nBATCH            = 8\nDEVICE           = 0                # GPU id or 'cpu'\nPSEUDO_CONF_TH   = 0.6              # confidence threshold for accepting teacher preds\nMAX_PSEUDO       = None             # set e.g. 500 to limit pseudo-labeling for speed\n\n# ============================================================\n# 1) Split dataset into labeled/unlabeled (keeping labels with labeled split)\n# ============================================================\nall_train_imgs = [p for p in glob.glob(f\"{BASE_DATASET}/train/images/*.*\")\n                  if p.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"))]\nrandom.shuffle(all_train_imgs)\n\nsplit_idx = int(len(all_train_imgs) * LABELED_FRACTION)\nlabeled_imgs   = all_train_imgs[:split_idx]\nunlabeled_imgs = all_train_imgs[split_idx:]\n\ndef safe_copy_pairs(image_paths, dst_root):\n    \"\"\"Copy images and their YOLO label .txt (if exists) to dst_root/images, dst_root/labels.\"\"\"\n    os.makedirs(f\"{dst_root}/images\", exist_ok=True)\n    os.makedirs(f\"{dst_root}/labels\", exist_ok=True)\n    for img in image_paths:\n        base = os.path.splitext(os.path.basename(img))[0]\n        lbl  = img.replace(\"/images/\", \"/labels/\").rsplit(\".\", 1)[0] + \".txt\"\n        shutil.copy(img, f\"{dst_root}/images/{os.path.basename(img)}\")\n        if os.path.exists(lbl):\n            shutil.copy(lbl, f\"{dst_root}/labels/{base}.txt\")\n\nsafe_copy_pairs(labeled_imgs,   LABELED_PATH)\nsafe_copy_pairs(unlabeled_imgs, UNLABELED_PATH)\n\nprint(f\"‚úÖ Split ‚Üí Labeled: {len(labeled_imgs)} | Unlabeled: {len(unlabeled_imgs)}\")\n\n# (Optional) quick integrity echo\nlab_img_names = {os.path.splitext(f)[0] for f in os.listdir(f\"{LABELED_PATH}/images\")}\nlab_lbl_names = {os.path.splitext(f)[0] for f in os.listdir(f\"{LABELED_PATH}/labels\")}\nprint(f\"üß© Integrity (labeled): images={len(lab_img_names)} labels={len(lab_lbl_names)}  missing_labels={len(lab_img_names - lab_lbl_names)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:28.495892Z","iopub.execute_input":"2025-12-16T09:04:28.496418Z","iopub.status.idle":"2025-12-16T09:04:33.720512Z","shell.execute_reply.started":"2025-12-16T09:04:28.496392Z","shell.execute_reply":"2025-12-16T09:04:33.719315Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Split ‚Üí Labeled: 3214 | Unlabeled: 12859\nüß© Integrity (labeled): images=3214 labels=1591  missing_labels=1623\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# 2) Build labeled YAML for Teacher training\n# ============================================================\nimport yaml as pyyaml\n\nDATA_YAML_LABELED = \"/kaggle/working/ts_labeled.yaml\"\n\nwith open(DATA_YAML_LABELED, \"w\") as f:\n    pyyaml.safe_dump({\n        \"train\": f\"{LABELED_PATH}/images\",\n        \"val\": f\"{BASE_DATASET}/valid/images\",\n        \"test\": f\"{BASE_DATASET}/test/images\",\n        \"nc\": NUM_CLASSES,\n        \"names\": CLASS_NAMES\n    }, f, sort_keys=False)\n\nprint(open(DATA_YAML_LABELED).read())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:33.722054Z","iopub.execute_input":"2025-12-16T09:04:33.722395Z","iopub.status.idle":"2025-12-16T09:04:33.732955Z","shell.execute_reply.started":"2025-12-16T09:04:33.722371Z","shell.execute_reply":"2025-12-16T09:04:33.731633Z"}},"outputs":[{"name":"stdout","text":"train: /kaggle/working/ts_labeled/images\nval: /kaggle/working/dataset/valid/images\ntest: /kaggle/working/dataset/test/images\nnc: 7\nnames:\n- Aluminium\n- Glass\n- Tag\n- 'cardboard '\n- ' rigid_plastic'\n- soft_plastic\n- wood\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\n\n# REMOVE CUDA COMPLETELY (not empty string)\nif \"CUDA_VISIBLE_DEVICES\" in os.environ:\n    del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n\nprint(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:33.737393Z","iopub.execute_input":"2025-12-16T09:04:33.737741Z","iopub.status.idle":"2025-12-16T09:04:33.795350Z","shell.execute_reply.started":"2025-12-16T09:04:33.737712Z","shell.execute_reply":"2025-12-16T09:04:33.793296Z"}},"outputs":[{"name":"stdout","text":"CUDA_VISIBLE_DEVICES = None\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ============================================================\n# 3) Train Teacher on the labeled subset\n# =====================================\nimport torch\nfrom ultralytics import YOLO\n\nprint(\"CUDA available:\", torch.cuda.is_available())\n\nteacher = YOLO(\"yolo12n-seg.yaml\").load(\"yolo12n.pt\")\n\nteacher_results = teacher.train(\n    data=DATA_YAML_LABELED,\n    epochs=TEACHER_EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH,\n    device=\"cpu\",     # CPU only\n    amp=False,        # AMP OFF\n    project=\"/kaggle/working/ts_runs\",\n    name=\"teacher_yolo12_seg\",\n    exist_ok=True,\n    patience=10\n)\n\nteacher_best = f\"{teacher_results.save_dir}/weights/best.pt\"\nteacher = YOLO(teacher_best)\n\nprint(\"‚úÖ Training started successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:04:33.796524Z","iopub.execute_input":"2025-12-16T09:04:33.796896Z","iopub.status.idle":"2025-12-16T19:25:37.619720Z","shell.execute_reply.started":"2025-12-16T09:04:33.796864Z","shell.execute_reply":"2025-12-16T19:25:37.617495Z"}},"outputs":[{"name":"stdout","text":"CUDA available: False\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to 'yolo12n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 130.5MB/s 0.0s\nTransferred 691/753 items from pretrained weights\nUltralytics 8.3.239 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon CPU @ 2.20GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/ts_labeled.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12n-seg.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=teacher_yolo12_seg, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=yolo12n.pt, profile=False, project=/kaggle/working/ts_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/ts_runs/teacher_yolo12_seg, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=7\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 21        [14, 17, 20]  1    684805  ultralytics.nn.modules.head.Segment          [7, 32, 64, [64, 128, 256]]   \nYOLO12n-seg summary: 294 layers, 2,822,181 parameters, 2,822,165 gradients\n\nTransferred 702/753 items from pretrained weights\nFreezing layer 'model.21.dfl.conv.weight'\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1580.9¬±501.2 MB/s, size: 131.2 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ts_labeled/labels... 1591 images, 1627 backgrounds, 16 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3214/3214 634.8it/s 5.1s0.1s\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/09_frame_003040_PNG.rf.5f782661d227b778a07faf40657558d0.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/AluCan17_jpg.rf.e8c660b2afd30c10e6478aaea5ca8e05.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0977      1.0209]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass119_jpg.rf.8b4566211b1bd5dd3e08975aa5c426ce.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0374]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass12_jpg.rf.228ff81e4e131c5af7357928561dc3c3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1286      1.1412]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass383_jpg.rf.582d1d265d26d14088fccad7344e9305.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0455]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass389_jpg.rf.3235a550d4955a229bc299974519b982.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0261]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass42_jpg.rf.14cd2c9f66e5d6209287b9fb5cbb6ada.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0234      1.1748]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass49_jpg.rf.3f660a681976ceadd26403062c38f00f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0818]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass61_jpg.rf.4afddebca509a4cde91c5d35db8c9381.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0561]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Glass75_jpg.rf.b6e587a8b645dc14210ed8abc81c9e78.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0154]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/Image__2023-02-22__16-20-21_bmp_jpg.rf.b10f0473e0f6767ad7c1dac42608ecaf.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0112]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/PET1-544_jpg.rf.c3baf4669cfa9d5ac843c5ea00ba0efd.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.145]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/PET1-548_jpg.rf.3bc268e050cfe366234a3fa030b13e75.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0649]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/PET1-550_jpg.rf.229ac61fd68471779caaef6d397d254b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1814]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/PET1-575_jpg.rf.a5272fdc61b5d75476029c14e34a0af1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0277]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/PET1-621_jpg.rf.c37bad8e23eb4a1e9cb9396688807d78.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0664]\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/ts_labeled/images/PET1-711_jpg.rf.91e87881bd16f7443693edf295cd9f30.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0334]\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/ts_labeled/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1104.3¬±466.5 MB/s, size: 54.8 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/valid/labels... 1290 images, 9 backgrounds, 20 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1290/1290 634.7it/s 2.0s<0.0s\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/01_frame_040300_PNG.rf.c5140dc39296ee80931c1cc0c3cee9ee.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0881]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/08_frame_012100_PNG.rf.f4b2be3bc7ee1a3c5cd806a515abbd02.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/AluCan29_jpg.rf.931d106191ef0eeb3f63ce3556281b8b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.052]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass107_jpg.rf.2f4f1734eee603a601c916ae5a32d501.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0615]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass128_jpg.rf.673fb32f860feb4848d5a148cbbf32c9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2417]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass138_jpg.rf.76a2ac8e1838fb6c01c99b5071eb0ca9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0137]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass142_jpg.rf.4c2629d042d2b3448e7ebd17d59cf9a8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.222]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass278_jpg.rf.207f90ac467970e1ac71ad2e9386bf47.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2458]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass412_jpg.rf.ba16ca0c33e4f1c975164f21c32a8dfa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0182]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass479_jpg.rf.097ae1546aa8f27a310a6fad350331eb.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1384      1.2161]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass498_jpg.rf.06e48e39b6cb7fb3ac9f66f74fd2a2f0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1478]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass62_jpg.rf.63d80aa4670ec62cbe1ba05ceb6708a9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.3604      1.4424]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Glass65_jpg.rf.c31e41898cbc71a1102582456966f5fa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1677      1.0856]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/HDPEM35_jpg.rf.c30029f738b5b17207de5c166a95c7c7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1182      1.0338]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/Image__2023-02-22__16-53-37_bmp_jpg.rf.a90e1e71c5159411ef31c6358b6604ef.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1523      1.1715]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/PET1-537_jpg.rf.fda8c3cf28284371176769a9b9962e94.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1228]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/PET1-594_jpg.rf.75cc97f7e6f7ffb22073c7672621e85b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/PET1-606_jpg.rf.20a55da28ac397b412e24a2224a50e6b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0526]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/PET1-610_jpg.rf.68134c59a3a8d70c42d9f737a2a0cdd2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0733]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/PET1-654_jpg.rf.d0c99106fb86dfd1f0171483d2bf6200.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0137]\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/valid/images/PET1-660_jpg.rf.5a94be46b51ed1c6e2035eb8555d03b9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0124]\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/valid/labels.cache\nPlotting labels to /kaggle/working/ts_runs/teacher_yolo12_seg/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 122 weight(decay=0.0), 133 weight(decay=0.0005), 132 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 0 dataloader workers\nLogging results to \u001b[1m/kaggle/working/ts_runs/teacher_yolo12_seg\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/10         0G       1.69      4.492      4.352      1.701          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 7.8s/it 52:14<7.0ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 9.2s/it 12:139.5ss\n                   all       1270       4483      0.272      0.212      0.187     0.0952      0.229      0.189      0.156     0.0639\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/10         0G      1.747      3.706      4.096      1.727         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 8.0s/it 53:01<7.0ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 9.0s/it 12:029.1ss\n                   all       1270       4483      0.376      0.227      0.191     0.0935      0.346      0.181      0.149     0.0704\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/10         0G      1.786      3.611      3.774      1.739          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 7.7s/it 51:15<7.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 6.9s/it 9:138.9ss\n                   all       1270       4483       0.34      0.296      0.182     0.0911      0.319      0.269      0.154     0.0678\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/10         0G      1.744      3.534      3.533      1.748         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 8.0s/it 53:27<7.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 7.5s/it 10:01.8ss\n                   all       1270       4483      0.368      0.282       0.23      0.119      0.311      0.218      0.155     0.0597\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/10         0G      1.685      3.471       3.03      1.702         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 7.9s/it 52:28<6.9ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 7.1s/it 9:286.9ss\n                   all       1270       4483      0.364      0.377      0.304      0.174      0.331      0.349      0.246      0.102\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/10         0G      1.618      3.302      3.193      1.642          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 7.7s/it 51:21<7.0ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 6.4s/it 8:346.2ss\n                   all       1270       4483      0.617      0.332      0.371      0.198      0.591      0.319      0.327      0.151\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/10         0G      1.549      3.215      3.049        1.6          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 8.1s/it 53:54<6.9ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 6.1s/it 8:116.5ss\n                   all       1270       4483      0.533      0.366       0.38      0.226      0.523      0.354      0.375      0.184\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/10         0G      1.514      3.128      2.761       1.57          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 7.6s/it 50:58<7.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 6.4s/it 8:326.5ss\n                   all       1270       4483      0.467      0.479      0.447      0.282      0.449      0.455      0.411       0.21\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/10         0G      1.481      3.049      2.737      1.536         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 7.5s/it 49:43<6.7ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 6.4s/it 8:306.5ss\n                   all       1270       4483      0.549      0.502      0.506      0.324      0.521      0.479      0.465      0.253\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/10         0G      1.426      3.015      2.629      1.505         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400/400 7.4s/it 49:35<6.7ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 6.1s/it 8:106.1ss\n                   all       1270       4483      0.582      0.511      0.523      0.343      0.568      0.484      0.481      0.261\n\n10 epochs completed in 10.217 hours.\nOptimizer stripped from /kaggle/working/ts_runs/teacher_yolo12_seg/weights/last.pt, 6.0MB\nOptimizer stripped from /kaggle/working/ts_runs/teacher_yolo12_seg/weights/best.pt, 6.0MB\n\nValidating /kaggle/working/ts_runs/teacher_yolo12_seg/weights/best.pt...\nUltralytics 8.3.239 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon CPU @ 2.20GHz)\nYOLO12n-seg summary (fused): 172 layers, 2,810,509 parameters, 0 gradients\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 5.6s/it 7:285.6ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all       1270       4483      0.581      0.511      0.523      0.344      0.564      0.486      0.481      0.261\n             Aluminium        151        154      0.955      0.331      0.543      0.389      0.981      0.331      0.543      0.395\n                 Glass        104        116      0.686      0.659      0.756      0.542      0.691      0.621      0.681      0.283\n                   Tag        267        301      0.451      0.505      0.459      0.261       0.45      0.488      0.446      0.227\n            cardboard         566       2312      0.576      0.391      0.429       0.22      0.542      0.345      0.361       0.14\n         rigid_plastic        609        682       0.66      0.632      0.663      0.493      0.626      0.591        0.6       0.32\n          soft_plastic        429        895      0.526      0.145      0.235      0.101      0.434      0.109      0.155       0.05\n                  wood         23         23      0.214      0.913      0.573      0.399      0.222      0.913      0.581      0.413\nSpeed: 5.3ms preprocess, 315.5ms inference, 0.0ms loss, 17.0ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/ts_runs/teacher_yolo12_seg\u001b[0m\n‚úÖ Training started successfully\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================\n# 4) Generate pseudo-labels on unlabeled images with Teacher\n# ============================================================\nto_label = unlabeled_imgs if MAX_PSEUDO is None else unlabeled_imgs[:MAX_PSEUDO]\nprint(f\"üìù Pseudo-labeling {len(to_label)} unlabeled images (conf ‚â• {PSEUDO_CONF_TH})\")\n\ndef write_seg_label_file(out_txt, classes, masks_xy, orig_shape):\n    \"\"\"\n    Write YOLO segmentation polygons to txt:\n    <cls> x1 y1 x2 y2 ... (normalized)\n    \"\"\"\n    oh, ow = orig_shape  # H, W\n    with open(out_txt, \"w\") as f:\n        for cls_id, poly in zip(classes, masks_xy):\n            if poly is None or len(poly) < 3:\n                continue\n            # normalize polygon\n            poly = np.array(poly, dtype=np.float32)\n            poly[:, 0] = np.clip(poly[:, 0] / ow, 0.0, 1.0)\n            poly[:, 1] = np.clip(poly[:, 1] / oh, 0.0, 1.0)\n            coords = \" \".join([f\"{x:.6f}\" for x in poly.reshape(-1)])\n            f.write(f\"{int(cls_id)} {coords}\\n\")\n\nfor img_path in tqdm(to_label, desc=\"Generating pseudo-labels\"):\n    # Single-image predict (faster if batched, but simple & robust here)\n    results = teacher.predict(source=img_path, imgsz=IMGSZ, conf=PSEUDO_CONF_TH, save=False, verbose=False)\n    if not results:\n        continue\n    r = results[0]\n    if r.masks is None or len(r.boxes) == 0:\n        continue\n\n    # Prepare output files\n    base = os.path.splitext(os.path.basename(img_path))[0]\n    out_img = f\"{PSEUDO_PATH}/images/{os.path.basename(img_path)}\"\n    out_lbl = f\"{PSEUDO_PATH}/labels/{base}.txt\"\n\n    # filter instances by conf\n    confs = r.boxes.conf.cpu().numpy()\n    keep_idx = np.where(confs >= PSEUDO_CONF_TH)[0]\n    if keep_idx.size == 0:\n        continue\n\n    # Extract classes & polygons for kept instances\n    classes = []\n    masks_xy = []\n    for i in keep_idx:\n        # masks.xy is a list of polygons; some instances may have multiple polygons (holes). Use largest.\n        if r.masks is None or r.masks.xy is None:\n            continue\n        polys = r.masks.xy[i]  # list of (N_i, 2) ndarray or single (N,2) depending on Ultralytics version\n        if isinstance(polys, list):\n            # choose largest polygon by area\n            areas = [cv2.contourArea(np.array(p, dtype=np.float32)) for p in polys if len(p) >= 3]\n            if len(areas) == 0:\n                continue\n            poly = polys[int(np.argmax(areas))]\n        else:\n            poly = polys\n        if poly is None or len(poly) < 3:\n            continue\n        classes.append(int(r.boxes.cls[i].item()) if hasattr(r.boxes, \"cls\") else 0)\n        masks_xy.append(poly)\n\n    if len(masks_xy) == 0:\n        continue\n\n    # Save label + image copy\n    h, w = r.orig_shape  # (H, W)\n    write_seg_label_file(out_lbl, classes, masks_xy, (h, w))\n    shutil.copy(img_path, out_img)\n\nprint(\"‚úÖ Pseudo-labels done.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T19:25:37.621493Z","iopub.execute_input":"2025-12-16T19:25:37.622302Z","iopub.status.idle":"2025-12-16T20:26:13.292803Z","shell.execute_reply.started":"2025-12-16T19:25:37.622264Z","shell.execute_reply":"2025-12-16T20:26:13.289768Z"}},"outputs":[{"name":"stdout","text":"üìù Pseudo-labeling 12859 unlabeled images (conf ‚â• 0.6)\n","output_type":"stream"},{"name":"stderr","text":"Generating pseudo-labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12859/12859 [1:00:35<00:00,  3.54it/s]","output_type":"stream"},{"name":"stdout","text":"‚úÖ Pseudo-labels done.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import yaml\nimport glob, shutil, os\n\n# ============================================================\n# 5) Merge labeled and pseudo-labeled into one training set\n# ============================================================\ndef merge_dir(src, dst):\n    os.makedirs(dst, exist_ok=True)\n    for f in glob.glob(f\"{src}/*\"):\n        shutil.copy(f, f\"{dst}/{os.path.basename(f)}\")\n\nmerge_dir(f\"{LABELED_PATH}/images\", f\"{MERGED_PATH}/images\")\nmerge_dir(f\"{LABELED_PATH}/labels\", f\"{MERGED_PATH}/labels\")\nmerge_dir(f\"{PSEUDO_PATH}/images\", f\"{MERGED_PATH}/images\")\nmerge_dir(f\"{PSEUDO_PATH}/labels\", f\"{MERGED_PATH}/labels\")\n\nDATA_YAML_MERGED = \"/kaggle/working/ts_merged.yaml\"\n\nwith open(DATA_YAML_MERGED, \"w\") as f:\n    yaml.safe_dump(\n        {\n            \"train\": f\"{MERGED_PATH}/images\",\n            \"val\": f\"{BASE_DATASET}/valid/images\",\n            \"test\": f\"{BASE_DATASET}/test/images\",\n            \"nc\": NUM_CLASSES,\n            \"names\": CLASS_NAMES,\n        },\n        f,\n        sort_keys=False,\n    )\n\n# print statement \nprint(open(DATA_YAML_MERGED).read())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T20:26:13.295830Z","iopub.execute_input":"2025-12-16T20:26:13.296423Z","iopub.status.idle":"2025-12-16T20:26:17.421478Z","shell.execute_reply.started":"2025-12-16T20:26:13.296394Z","shell.execute_reply":"2025-12-16T20:26:17.420298Z"}},"outputs":[{"name":"stdout","text":"train: /kaggle/working/ts_merged/images\nval: /kaggle/working/dataset/valid/images\ntest: /kaggle/working/dataset/test/images\nnc: 7\nnames:\n- Aluminium\n- Glass\n- Tag\n- 'cardboard '\n- ' rigid_plastic'\n- soft_plastic\n- wood\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nfrom ultralytics import YOLO\n\n# ============================================================\n# 6) Train Student on merged dataset\n# ============================================================\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n\nstudent = YOLO(\"yolo12n-seg.yaml\").load(\"yolo12n.pt\")\n\nstudent_results = student.train(\n    data=DATA_YAML_MERGED,\n    epochs=STUDENT_EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH,\n    device=DEVICE,               # ‚úÖ no invalid CUDA request\n    project=\"/kaggle/working/ts_runs\",\n    name=\"student_yolo12_seg\",\n    exist_ok=True,\n    patience=10,\n    amp=True\n)\n\nstudent_best = f\"{student_results.save_dir}/weights/best.pt\"\nprint(\"‚úÖ Student best:\", student_best)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}